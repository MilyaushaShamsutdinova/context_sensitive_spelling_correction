{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intall libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install nltk\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling correction\n",
    "\n",
    "inspired by Norvig's spelling correction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Load n-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r\"models/trigram_model_shakespeare.pkl\", \"rb\") as f:\n",
    "    ngram_model = pickle.load(f)\n",
    "\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toe': 9.835997680775283e-05, 'aufidius': 8.80062950385157e-05, 'king': 8.80062950385157e-05, 'rich': 8.80062950385157e-05, 'chamber': 8.80062950385157e-05, 'lord': 8.80062950385157e-05, 'commanding': 8.80062950385157e-05, 'apollo': 9.318313592313427e-05, 'comfort': 8.80062950385157e-05, 'pompey': 8.80062950385157e-05, 'soldier': 8.80062950385157e-05, 'traveller': 8.80062950385157e-05, 'desire': 8.80062950385157e-05}\n"
     ]
    }
   ],
   "source": [
    "print(ngram_model.get((\"the\", \"great\"), {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12072\n"
     ]
    }
   ],
   "source": [
    "vocab = set(word for counts in ngram_model.values() for word in counts)\n",
    "vocab_size = len(set(word for counts in ngram_model.values() for word in counts))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate possible candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aat',\n",
       " 'acat',\n",
       " 'act',\n",
       " 'at',\n",
       " 'bat',\n",
       " 'bcat',\n",
       " 'ca',\n",
       " 'caa',\n",
       " 'caat',\n",
       " 'cab',\n",
       " 'cabt',\n",
       " 'cac',\n",
       " 'cact',\n",
       " 'cad',\n",
       " 'cadt',\n",
       " 'cae',\n",
       " 'caet',\n",
       " 'caf',\n",
       " 'caft',\n",
       " 'cag',\n",
       " 'cagt',\n",
       " 'cah',\n",
       " 'caht',\n",
       " 'cai',\n",
       " 'cait',\n",
       " 'caj',\n",
       " 'cajt',\n",
       " 'cak',\n",
       " 'cakt',\n",
       " 'cal',\n",
       " 'calt',\n",
       " 'cam',\n",
       " 'camt',\n",
       " 'can',\n",
       " 'cant',\n",
       " 'cao',\n",
       " 'caot',\n",
       " 'cap',\n",
       " 'capt',\n",
       " 'caq',\n",
       " 'caqt',\n",
       " 'car',\n",
       " 'cart',\n",
       " 'cas',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'cata',\n",
       " 'catb',\n",
       " 'catc',\n",
       " 'catd',\n",
       " 'cate',\n",
       " 'catf',\n",
       " 'catg',\n",
       " 'cath',\n",
       " 'cati',\n",
       " 'catj',\n",
       " 'catk',\n",
       " 'catl',\n",
       " 'catm',\n",
       " 'catn',\n",
       " 'cato',\n",
       " 'catp',\n",
       " 'catq',\n",
       " 'catr',\n",
       " 'cats',\n",
       " 'catt',\n",
       " 'catu',\n",
       " 'catv',\n",
       " 'catw',\n",
       " 'catx',\n",
       " 'caty',\n",
       " 'catz',\n",
       " 'cau',\n",
       " 'caut',\n",
       " 'cav',\n",
       " 'cavt',\n",
       " 'caw',\n",
       " 'cawt',\n",
       " 'cax',\n",
       " 'caxt',\n",
       " 'cay',\n",
       " 'cayt',\n",
       " 'caz',\n",
       " 'cazt',\n",
       " 'cbat',\n",
       " 'cbt',\n",
       " 'ccat',\n",
       " 'cct',\n",
       " 'cdat',\n",
       " 'cdt',\n",
       " 'ceat',\n",
       " 'cet',\n",
       " 'cfat',\n",
       " 'cft',\n",
       " 'cgat',\n",
       " 'cgt',\n",
       " 'chat',\n",
       " 'cht',\n",
       " 'ciat',\n",
       " 'cit',\n",
       " 'cjat',\n",
       " 'cjt',\n",
       " 'ckat',\n",
       " 'ckt',\n",
       " 'clat',\n",
       " 'clt',\n",
       " 'cmat',\n",
       " 'cmt',\n",
       " 'cnat',\n",
       " 'cnt',\n",
       " 'coat',\n",
       " 'cot',\n",
       " 'cpat',\n",
       " 'cpt',\n",
       " 'cqat',\n",
       " 'cqt',\n",
       " 'crat',\n",
       " 'crt',\n",
       " 'csat',\n",
       " 'cst',\n",
       " 'ct',\n",
       " 'cta',\n",
       " 'ctat',\n",
       " 'ctt',\n",
       " 'cuat',\n",
       " 'cut',\n",
       " 'cvat',\n",
       " 'cvt',\n",
       " 'cwat',\n",
       " 'cwt',\n",
       " 'cxat',\n",
       " 'cxt',\n",
       " 'cyat',\n",
       " 'cyt',\n",
       " 'czat',\n",
       " 'czt',\n",
       " 'dat',\n",
       " 'dcat',\n",
       " 'eat',\n",
       " 'ecat',\n",
       " 'fat',\n",
       " 'fcat',\n",
       " 'gat',\n",
       " 'gcat',\n",
       " 'hat',\n",
       " 'hcat',\n",
       " 'iat',\n",
       " 'icat',\n",
       " 'jat',\n",
       " 'jcat',\n",
       " 'kat',\n",
       " 'kcat',\n",
       " 'lat',\n",
       " 'lcat',\n",
       " 'mat',\n",
       " 'mcat',\n",
       " 'nat',\n",
       " 'ncat',\n",
       " 'oat',\n",
       " 'ocat',\n",
       " 'pat',\n",
       " 'pcat',\n",
       " 'qat',\n",
       " 'qcat',\n",
       " 'rat',\n",
       " 'rcat',\n",
       " 'sat',\n",
       " 'scat',\n",
       " 'tat',\n",
       " 'tcat',\n",
       " 'uat',\n",
       " 'ucat',\n",
       " 'vat',\n",
       " 'vcat',\n",
       " 'wat',\n",
       " 'wcat',\n",
       " 'xat',\n",
       " 'xcat',\n",
       " 'yat',\n",
       " 'ycat',\n",
       " 'zat',\n",
       " 'zcat'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits1(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edits1(\"cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14352"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edits2(\"cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(word, vocab, max_distance=2):\n",
    "    candidates = {word} if word in vocab else set()\n",
    "    valid_edits1 = edits1(word) & vocab\n",
    "    if valid_edits1:\n",
    "        return valid_edits1\n",
    "\n",
    "    if max_distance > 1:\n",
    "        word_edits2 = edits2(word)\n",
    "        return word_edits2 & vocab\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'calf', 'can', 'cap', 'car', 'cat'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_candidates(\"caf\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12\n",
    "\n",
    "def get_ngram_probability(context, word):\n",
    "    \"\"\"Compute P(word | context) using the trained N-gram model.\"\"\"\n",
    "    ngram = tuple(context) #+ (word,)\n",
    "    if ngram not in ngram_model:\n",
    "        return EPS\n",
    "    if word not in ngram_model[ngram]:\n",
    "        return EPS\n",
    "    return ngram_model.get(ngram, EPS)[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-12"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngram_probability((\"the\", \"great\"), \"shakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.80062950385157e-05"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngram_probability((\"the\", \"great\"), \"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "n=3\n",
    "\n",
    "def correct_sentence(sentence, vocab):\n",
    "    words = nltk.word_tokenize(sentence.lower())\n",
    "    corrected_words = []\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in vocab:\n",
    "            corrected_words.append(word)\n",
    "            continue\n",
    "\n",
    "        context = tuple(corrected_words[-(n-1):]) if i >= n-1 else tuple(corrected_words)\n",
    "        candidates = generate_candidates(word, vocab)\n",
    "\n",
    "        best_candidate = max(candidates, key=lambda w: get_ngram_probability(context, w))\n",
    "        corrected_words.append(best_candidate)\n",
    "    return ' '.join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to be or not to be'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence(\"to be or not to ve\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
